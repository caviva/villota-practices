# ğŸ§ª Test Case Evaluator - UFSCar

Sistema de avaliaÃ§Ã£o de casos de teste baseado em 25 melhores prÃ¡ticas de engenharia de software, utilizando OpenAI Assistants API.

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto Ã© composto por duas aplicaÃ§Ãµes que trabalham em conjunto:

- **Backend (API)**: Servidor Node.js/Express que atua como intermediÃ¡rio com a OpenAI Assistants API
- **Frontend**: Interface web desenvolvida em Vue.js 3 + Vite + Tailwind CSS

O sistema permite que desenvolvedores e estudantes avaliem a qualidade de seus casos de teste contra 25 melhores prÃ¡ticas divididas em duas categorias:
- **Common Sense (CS)**: 14 prÃ¡ticas de senso comum
- **Literature Supported (LS)**: 11 prÃ¡ticas respaldadas por literatura acadÃªmica

## ğŸ¯ Funcionalidades

- âœ… AvaliaÃ§Ã£o automÃ¡tica de cÃ³digo de teste em mÃºltiplas linguagens (Python, Java, JavaScript, C++, etc.)
- âœ… AnÃ¡lise baseada em 25 melhores prÃ¡ticas de testes de software
- âœ… PontuaÃ§Ã£o de conformidade por categoria e geral
- âœ… SugestÃ£o de cÃ³digo melhorado
- âœ… Interface intuitiva e responsiva
- âœ… CÃ³pia rÃ¡pida do cÃ³digo sugerido

## ğŸ—ï¸ Arquitetura

```
villota-practices/
â”œâ”€â”€ api-practices/          # Backend (Node.js + Express)
â”‚   â”œâ”€â”€ server.js          # Servidor principal
â”‚   â”œâ”€â”€ package.json       # DependÃªncias do backend
â”‚   â”œâ”€â”€ Dockerfile         # ConfiguraÃ§Ã£o Docker do backend
â”‚   â””â”€â”€ .env.example       # Template de variÃ¡veis de ambiente
â”‚
â”œâ”€â”€ code-evaluator/        # Frontend (Vue.js 3)
â”‚   â”œâ”€â”€ src/              # CÃ³digo fonte
â”‚   â”œâ”€â”€ public/           # Arquivos pÃºblicos
â”‚   â”œâ”€â”€ package.json      # DependÃªncias do frontend
â”‚   â”œâ”€â”€ Dockerfile        # ConfiguraÃ§Ã£o Docker do frontend
â”‚   â”œâ”€â”€ nginx.conf        # ConfiguraÃ§Ã£o do Nginx
â”‚   â””â”€â”€ .env.example      # Template de variÃ¡veis de ambiente
â”‚
â”œâ”€â”€ docker-compose.yml    # OrquestraÃ§Ã£o dos containers
â”œâ”€â”€ .env.example          # Template de variÃ¡veis de ambiente global
â””â”€â”€ README.md            # Este arquivo
```

## ğŸš€ Requisitos Previos

- [Docker](https://www.docker.com/get-started) (versÃ£o 20.10 ou superior)
- [Docker Compose](https://docs.docker.com/compose/install/) (versÃ£o 1.29 ou superior)
- Conta na [OpenAI Platform](https://platform.openai.com/)
- Chave de API da OpenAI
- Assistente OpenAI configurado

## âš™ï¸ ConfiguraÃ§Ã£o do OpenAI Assistant

Antes de executar o projeto, vocÃª precisa criar e configurar um assistente no OpenAI Playground:

### 1. Acesse o OpenAI Playground
VÃ¡ para: [https://platform.openai.com/playground](https://platform.openai.com/playground)

### 2. Crie um Novo Assistente
Clique em "Assistants" e depois em "Create"

### 3. Configure o Assistente com os Seguintes ParÃ¢metros:

**Nome:**
```
UFSCar
```

**Modelo:**
```
gpt-4-turbo
```

**System Prompt:**
```
You are an expert in software testing and best practices for writing test cases. Your task is to analyze the provided test code and compare it against the **25 best practices** listed below.

ğŸ“Œ **Strict Output Requirements**
- Always return the response in **valid JSON format** following the provided JSON Schema.
- Do **not include any text or explanations** outside of the JSON structure.
- Every response **must contain all 25 best practices** evaluations, even if some are not applicable.
- The `"status"` field must always be one of the following:
  - `"âœ”ï¸"` (Met)
  - `"âŒ"` (Not Met)
  - `"âšª"` (Not Applicable)
- The `"compliance_score"` must be calculated as **(âœ”ï¸ practices / 25) * 100** and returned as a string with a percentage (e.g., `"85%"`).
- The "suggested_code" must be a fully formatted, improved version of the test case, implementing all applicable best practices while maintaining the original logic. The improvements should follow the 25 best practices while ensuring that neither the test coverage nor the mutation score are affected. Any modifications should preserve the effectiveness of the test suite, ensuring that all edge cases and possible mutations remain properly validated.

ğŸ“Œ **Definition of the 25 Best Practices**
Each test case must be evaluated against these practices:

### **Common Sense Practices**
1ï¸âƒ£ **CS-01: Atomic Specification of Test Cases**  
   - Each test case must focus on a **single requirement** or behavior.
   - Independent test cases avoid false positives or negatives.

2ï¸âƒ£ **CS-02: Complete Independence of Test Cases**  
   - Test cases should not depend on other tests.
   - Independent tests allow for flexibility in execution.

3ï¸âƒ£ **CS-03: Coverage of Normal and Exceptional Flows**  
   - Test cases must check **both normal** and **edge case** scenarios.
   - Exception handling should be tested properly.

4ï¸âƒ£ **CS-04: Boundary Values Analysis**  
   - Tests should validate inputs at the **minimum, maximum, and just outside** boundaries.

5ï¸âƒ£ **CS-05: Complete Modularity of Test Cases**  
   - Tests should be **self-contained** and **reusable**.
   - Modular test cases improve maintainability.

6ï¸âƒ£ **CS-06: Detailed Analysis of Size and Complexity**  
   - Keep test cases **small and focused**.
   - Avoid unnecessary complexity in a single test.

7ï¸âƒ£ **CS-07: Complex Design for Fault Detection**  
   - Some complex test cases are needed to detect deep system issues.
   - Balance complexity with maintainability.

8ï¸âƒ£ **CS-08: Complete Maintenance of Test Code**  
   - Test code should be **regularly updated**.
   - Prioritize **readability** and **modularization**.

9ï¸âƒ£ **CS-09: Complete Traceability of Test Cases**  
   - Each test should be **linked** to a requirement.
   - Improves **debugging and change management**.

ğŸ”Ÿ **CS-10: Strict Use of Performance and Security Testing**  
   - Performance and security **must be tested** separately from functional tests.

1ï¸âƒ£1ï¸âƒ£ **CS-11: Regular Review of Test Cases**  
   - Test cases should be **periodically reviewed** to match changing requirements.

1ï¸âƒ£2ï¸âƒ£ **CS-12: Clear Understanding of Test Cases**  
   - Each test case should have a **clear, unambiguous purpose**.

1ï¸âƒ£3ï¸âƒ£ **CS-13: Structured Coverage of Testing Process**  
   - Use structured **integration testing approaches** (top-down, bottom-up).

1ï¸âƒ£4ï¸âƒ£ **CS-14: Complete Assurance of Test Code Quality**  
   - Use **test coverage metrics** but don't rely on them alone.

---

### **Literature-Supported Practices**
 **LS-01: Proper Utilization of Test Code Coverage**  
   - High coverage does not always mean **effective** tests.
   - Focus on quality, not just coverage percentage.

 **LS-02: Required Utilization of Missing Tests**  
   - Identify **gaps** in test coverage and **create missing tests**.

 **LS-03: Efficient Utilization of Test Code Coverage**  
   - Test coverage should include **fault patterns** and **edge cases**.

 **LS-04: Small Test Code Generation Footprint**  
   - Tests should **execute quickly** and **avoid unnecessary computations**.

 **LS-05: Complete Prioritization of Test Cases Design**  
   - Prioritize tests based on **functional and non-functional requirements**.

**LS-06: Responsible Addition of Test Code Maintenance**  
   - Keep the test suite **updated with fixed bugs** to prevent regressions.

 **LS-07: Suitable Utilization of Test Assertions**  
   - Use **assertions** effectively to detect **subtle faults**.

**LS-08: Responsible Addition of Test Debugging Comments**  
   - Document common **failure patterns** and **expected behaviors**.

**LS-09: Deterministic Design of Test Results**  
   - Tests must **always return the same results** given the same inputs.

**LS-10: Complete Avoidance of Test Side Effects**  
   - Tests must **not modify shared state** or cause dependencies between tests.

**LS-11: Suitable Utilization of Test Labels and Categories**  
   - Use **labels or categories** to organize test cases.

---

ğŸ“Œ **Mandatory JSON Format**
Every response **must** follow this structure:

```json
{
  "practices_evaluation": [
    {
      "title": "Best practice name",
      "status": "âœ”ï¸ / âŒ / âšª",
      "description": "Brief explanation of compliance or violation"
    }
    // Repeat for all 25 practices
  ],
  "compliance_score": "XX%",
  "suggested_code": "Improved test code"
}
```
```

**ConfiguraÃ§Ãµes Adicionais:**
- **Response Format**: `json_object`
- **Temperature**: `0.2`
- **Top P**: `0.3`
- **File Search**: Desabilitado
- **Code Interpreter**: Desabilitado
- **Functions**: Nenhuma

### 4. Salve e Copie o Assistant ID
ApÃ³s criar o assistente, copie o **Assistant ID** (formato: `asst_xxxxxxxxxxxxxxxxxxxxxxxx`). VocÃª precisarÃ¡ dele na configuraÃ§Ã£o.

## ğŸ”§ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clone o RepositÃ³rio
```bash
git clone <url-do-repositorio>
cd villota-practices
```

### 2. Configure as VariÃ¡veis de Ambiente
Copie o arquivo `.env.example` para `.env` e preencha com suas credenciais:

```bash
cp .env.example .env
```

Edite o arquivo `.env` e adicione suas credenciais:
```env
OPENAI_API_KEY=sk-proj-sua-chave-aqui
ASSISTANT_ID=asst_seu-assistant-id-aqui
```

### 3. Execute com Docker Compose
```bash
docker-compose up -d
```

Este comando irÃ¡:
- âœ… Construir as imagens Docker do backend e frontend
- âœ… Criar uma rede isolada para comunicaÃ§Ã£o entre os containers
- âœ… Iniciar o backend na porta 3000
- âœ… Iniciar o frontend na porta 80

### 4. Acesse a AplicaÃ§Ã£o
Abra seu navegador e acesse:
```
http://localhost
```

## ğŸ“– Como Usar

1. **Cole seu cÃ³digo de teste** na Ã¡rea de texto
2. **Clique em "Evaluate"** para iniciar a anÃ¡lise
3. **Aguarde** enquanto o assistente processa (pode levar alguns segundos)
4. **Visualize os resultados**:
   - PontuaÃ§Ã£o geral de conformidade
   - AvaliaÃ§Ã£o detalhada das 25 prÃ¡ticas
   - CÃ³digo sugerido com melhorias
5. **Copie o cÃ³digo melhorado** clicando no botÃ£o "Copy"

## ğŸ› ï¸ Comandos Ãšteis do Docker

### Visualizar logs dos containers
```bash
# Todos os containers
docker-compose logs -f

# Apenas o backend
docker-compose logs -f api

# Apenas o frontend
docker-compose logs -f frontend
```

### Parar os containers
```bash
docker-compose down
```

### Reconstruir as imagens
```bash
docker-compose up -d --build
```

### Verificar status dos containers
```bash
docker-compose ps
```

### Acessar o shell de um container
```bash
# Backend
docker-compose exec api sh

# Frontend
docker-compose exec frontend sh
```

## ğŸ” Troubleshooting

### Problema: "Failed to retrieve assistant details"
**SoluÃ§Ã£o**: Verifique se o `ASSISTANT_ID` estÃ¡ correto no arquivo `.env`

### Problema: "Error evaluating the code"
**SoluÃ§Ã£o**:
- Verifique se a `OPENAI_API_KEY` estÃ¡ vÃ¡lida
- Confirme que vocÃª tem crÃ©ditos disponÃ­veis na sua conta OpenAI
- Verifique os logs do backend: `docker-compose logs api`

### Problema: Frontend nÃ£o carrega
**SoluÃ§Ã£o**:
- Verifique se o container estÃ¡ rodando: `docker-compose ps`
- Verifique os logs: `docker-compose logs frontend`
- Certifique-se de que a porta 80 nÃ£o estÃ¡ sendo usada por outro serviÃ§o

### Problema: Backend nÃ£o responde
**SoluÃ§Ã£o**:
- Verifique os logs: `docker-compose logs api`
- Certifique-se de que a porta 3000 nÃ£o estÃ¡ sendo usada
- Verifique se as variÃ¡veis de ambiente estÃ£o configuradas corretamente

## ğŸ§ª Desenvolvimento Local (Sem Docker)

### Backend
```bash
cd api-practices
npm install
cp .env.example .env
# Edite o .env com suas credenciais
npm start
```

### Frontend
```bash
cd code-evaluator
npm install
cp .env.example .env
# Edite o .env com a URL da API (http://localhost:3000)
npm run dev
```

## ğŸ“Š Tecnologias Utilizadas

### Backend
- Node.js 18
- Express.js
- OpenAI SDK
- CORS
- dotenv

### Frontend
- Vue.js 3
- Vite
- Tailwind CSS
- Axios
- Vue Router
- Prism.js (syntax highlighting)

### DevOps
- Docker
- Docker Compose
- Nginx (servidor web para o frontend)

## ğŸ“ Estrutura das 25 Melhores PrÃ¡ticas

### Common Sense (CS) - 14 prÃ¡ticas
- CS-01 a CS-14: PrÃ¡ticas fundamentais de senso comum para testes

### Literature Supported (LS) - 11 prÃ¡ticas
- LS-01 a LS-11: PrÃ¡ticas respaldadas por pesquisas acadÃªmicas

Para detalhes completos de cada prÃ¡tica, consulte o System Prompt do assistente na seÃ§Ã£o de configuraÃ§Ã£o.

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:
- Reportar bugs
- Sugerir novas funcionalidades
- Melhorar a documentaÃ§Ã£o
- Enviar pull requests

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para fins educacionais na UFSCar (Universidade Federal de SÃ£o Carlos).

## ğŸ‘¥ Autores

Desenvolvido por estudantes e pesquisadores da UFSCar.

## ğŸ“ Suporte

Para questÃµes e suporte:
- Abra uma issue no repositÃ³rio
- Entre em contato com a equipe de desenvolvimento

---

**Nota**: Este projeto utiliza a API da OpenAI, que Ã© um serviÃ§o pago. Certifique-se de monitorar seu uso e custos na [plataforma OpenAI](https://platform.openai.com/usage).


